# jemdoc: menu{MENU}{index.html}, nofooter  
==Yuhao Ding 丁宇昊

~~~
{}{img_left}{photos/photo_Yuhao.jpeg}{alt text}{250px}{260px}

I got my Ph.D. degree in [https://ieor.berkeley.edu/ Industrial Engineering and Operations Research] from [https://www.berkeley.edu/ University of California, Berkeley], advised by [https://lavaei.ieor.berkeley.edu/ Javad Lavaei]. My research has been focused on the interdisciplinary problems in control, reinforcement learning, optimization and statistical learning. Most recently, I work on the reinforcement learning under the safety requirements and the time-varying environments.

*Email*: /yuhao_ding/ \[@\] berkeley \[DOT\] edu, \n

*[cv/CV_Yuhao_Nov.pdf CV]*
~~~

== News 
- September 2023: Two papers to appear in Conference on Neural Information Processing Systems (NeurIPS): [https://lavaei.ieor.berkeley.edu/Safe_MARL_2023_1.pdf Scalable Primal-Dual Actor-Critic Method for Safe Multi-Agent RL with General Utilities] and [https://hyunin-lee.github.io/assets/TempoAdaption_NSRL.pdf Tempo Adaption in Non-stationary Reinforcement Learning].
- August 2023: New paper on optimization landscape of dynamic programming: [https://lavaei.ieor.berkeley.edu/DP-One-Shot_2023_1.pdf The Landscape of the Optimal Control Problem: One-shot Optimization Versus Dynamic Programming].
- May 2023: New paper on multi-agent reinforcement learning: [https://lavaei.ieor.berkeley.edu/Safe_MARL_2023_1.pdf Scalable Primal-Dual Actor-Critic Method for Safe Multi-Agent RL with General Utilities].
- April 2023: I defended my PhD.
- March 2023: The paper [https://lavaei.ieor.berkeley.edu/Meta_Opt_2022_1.pdf Learning-to-Learn to Guide Random Search: Derivative-Free Meta Blackbox Optimization on Manifold] to appear in Learning for Dynamics & Control Conference (L4DC) as an oral presentation.
- March 2023: The paper [https://lavaei.ieor.berkeley.edu/Entropy_2023_1.pdf Local Analysis of Entropy-Regularized Stochastic Soft-Max Policy Gradient Methods] to appear in European Control Conference (ECC).
- February 2023: I gave a talk on [https://sites.google.com/view/saferl-seminar/home?authuser=0 safe reinforcement learning online seminar].
- January 2023: Our paper [pubs/MDP_Meta_2022_1.pdf A CMDP-within-online framework for Meta-Safe Reinforcement Learning] is accepted as a spotlight in International Conference on Learning Representations (ICLR).
- January 2023: Our paper [https://lavaei.ieor.berkeley.edu/MARL_Local_2022.pdf Scalable Multi-Agent Reinforcement Learning with General Utilities] is accepted for American Control Conference (ACC).
- January 2023: Our paper [pubs/2022-NS-RS-RL.pdf Non-stationary Risk-sensitive Reinforcement Learning] is accepted as an oral in AAAI Conference on Artificial Intelligence (AAAI).
- November 2022: New Paper on meta learning: [pubs/Meta_Black_box_Optimization.pdf Learning-to-Learn to Guide Random Search: Derivative-Free Meta Blackbox Optimization on Manifold].
- November 2022: Three papers to appear in AAAI Conference on Artificial Intelligence (AAAI): [pubs/2022-NS-RS-RL.pdf Non-stationary Risk-sensitive Reinforcement Learning], [pubs/2022-Convex-CMDP.pdf Convex Constrained Markov Decision Processes], and [https://arxiv.org/abs/2201.11965 Non-stationary Constrained Markov Decision Processes].
- October 2022: I organized a session on ``Recent Advances in Provably Efficient Reinforcement Learning with Safety Guarantee'' at the 2022 INFORMS Annual Meeting.
We were excited and honored to have a great team of speakers (alphabetical): Dongsheng Ding, Ming Jin, Alec Koppel and Donghao Ying.
- October 2022: New paper on reinforcement learning: [https://lavaei.ieor.berkeley.edu/MARL_Local_2022.pdf Scalable Multi-Agent Reinforcement Learning with General Utilities].
- May 2022: I started the internship at Amazon AWS AI Lab as an applied scientist intern.
- May 2022: New paper on reinforcement learning: [pubs/MDP_Meta_2022_1.pdf Provable Guarantees for Meta-Safe Reinforcement Learning].
- May 2022: New paper on reinforcement learning: [pubs/2022-Convex-CMDP.pdf Policy-based Primal-Dual Methods for Convex Constrained Markov Decision Processes].
- May 2022: New paper on reinforcement learning: [pubs/2022-NS-RS-RL.pdf Non-stationary Risk-sensitive Reinforcement Learning: Near-optimal Dynamic Regret, Adaptive Detection, and Separation Design].
- May 2022: I received the Marshall-Olivier-Rosenberger Fellowship given by UC Berkeley.
- Jan 2022: New paper on reinforcement learning: [https://arxiv.org/abs/2201.11965 Provably Efficient Primal-Dual Reinforcement Learning for CMDPs with Non-stationary Objectives and Constraints].
- Jan 2022: Two papers to appear in International Conference on Artificial Intelligence and Statistics (AISTATS): [https://arxiv.org/abs/2110.08923 A Dual Approach to Constrained Markov Decision Processes with Entropy Regularization], and [https://arxiv.org/abs/2110.10116 On the Global Optimum Convergence of Momentum-based Policy Gradient].
- Oct 2021: I gave a guest lecture on model-free reinforcement learning for IEOR 268 Applied Dynamic Programming at UC Berkeley.
- Oct 2021: I gave a talk for the session on Recent Advances in Data Efficient Reinforcement Learning with Policy Gradient Methods at the 2021 INFORMS Annual Meeting.
- Oct 2021: Two new papers posted on arXiv. In these papers, we derive the first set of global convergence results for stochastic policy gradient methods with [https://arxiv.org/abs/2110.10116 momentum] and [https://arxiv.org/abs/2110.10117 entropy].
- Oct 2021: New paper on constrained Markov decision processes: [https://arxiv.org/abs/2110.08923 A Dual Approach to Constrained Markov Decision Processes with Entropy Regularization].
- July 2021: The paper [pubs/2021-structured-online-opt.pdf Structured Projection-free Online Convex Optimization with Multi-point Bandit Feedback] to appear in 60th Conference on Decision and Control.
- June 2021: The paper [pubs/2021-time-variation-TAC.pdf Time-variation in online nonconvex optimization enables escaping from spurious local minima] has been conditionally accepted for IEEE Transactions on Automatic Control.
- May 2021: I started the research internship at Microsoft research.
- April 2021: The paper [pubs/2020-on-absence-TAC.pdf On the absence of spurious local trajectories in time-varying nonconvex optimization] has been conditionally accepted for IEEE Transactions on Automatic Control.
- January 2021: The paper [https://ieeexplore.ieee.org/document/9483303 Escaping spurious local minimum trajectories in online time-varying nonconvex optimization] has been selected as a best student paper finalist for 2021 American Control Conference.



